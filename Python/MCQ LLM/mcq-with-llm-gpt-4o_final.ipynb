{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T09:33:34.568499Z",
     "iopub.status.busy": "2024-08-12T09:33:34.568111Z",
     "iopub.status.idle": "2024-08-12T09:33:49.758190Z",
     "shell.execute_reply": "2024-08-12T09:33:49.756660Z",
     "shell.execute_reply.started": "2024-08-12T09:33:34.568468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /opt/conda/lib/python3.10/site-packages (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2\n",
    "import random\n",
    "import re\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T09:33:56.327416Z",
     "iopub.status.busy": "2024-08-12T09:33:56.326940Z",
     "iopub.status.idle": "2024-08-12T09:33:58.049564Z",
     "shell.execute_reply": "2024-08-12T09:33:58.048228Z",
     "shell.execute_reply.started": "2024-08-12T09:33:56.327368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key Terms for AI Governance 1The field of AI is rapidly evolving across different sectors and disparate industries, leaving business, technology and \n",
      "government professionals without a common lexicon and shared understanding of terms and phrases used in AI \n",
      "governance. Even a search to define \"artificial intelligence\" returns a range of definitions and examples. From the \n",
      "cinematic, like HAL 9000 from \"2001: A Space Odyssey,\" to the creative, like Midjourney and DALL-E generative art, \n",
      "to the common, like email autocorrect and mobile maps, the use cases and applications of AI continue to grow and \n",
      "expand into all aspects of life.\n",
      "This glossary is an update to the October 2023  release of IAPP's Key Terms for AI Governance. The updated \n",
      "version has been developed with reference to various materials and with valuable feedback from top experts \n",
      "in AI governance. It includes new terms and modifications to existing terms.\n",
      "The original glossary from June 2023 was developed with reference to numerous materials and designed to provide \n",
      "succinct, but nuanced, definitions and explanations for some of the most common terms related to AI today. \n",
      "The same methodology has been retained for the new updates. The explanations aim to present both policy and \n",
      "technical perspectives and add to the robust discourse on AI governance. Although there are some shared terms \n",
      "and definitions, this glossary is separate from the official IAPP Glossary of Privacy Terms .\n",
      "Key Terms for AI Governance\n",
      "TERM DEFINITION\n",
      "Accountability1The obligations and responsibilities of an AI system's developers and deployers to ensure \n",
      "the system operates in a manner that is ethical, fair, transparent and compliant with \n",
      "applicable rules and regulations (see also fairness  and transparency ). Accountability \n",
      "ensures the actions, decisions and outcomes of an AI system can be traced back to the \n",
      "entity responsible for it.\n",
      "AccuracyThe degree to which an AI system correctly performs its intended task. It is the measure \n",
      "of the system's performance and effectiveness in producing correct outputs based on its \n",
      "input data. Accuracy is a critical metric in evaluating the reliability of an AI model, especially \n",
      "in applications requiring high precision, such as medical diagnoses. A B C D E F G H I L M N O P R S T U V W Key termsKey Terms for AI Governance 2A B C D E F G H I L M N O P R S T U V W Key terms\n",
      "TERM DEFINITION\n",
      "Active learningA subfield of AI and machine learning  in which an algorithm selects some of the data \n",
      "it learns from. Instead of learning from all the data it is given, an active learning model \n",
      "requests additional data points that will help it learn the best. \n",
      "Adaptive learningA method that adjusts and tailors educational content to the specific needs, abilities \n",
      "and learning pace of individual students. The purpose of adaptive learning is to provide \n",
      "a personalized and optimized learning experience, catering to the diverse learning \n",
      "styles of students.\n",
      "Adversarial attackA safety  and security risk to the AI model that can be instigated by manipulating the model, \n",
      "such as by introducing malicious or deceptive input data . Such attacks can cause the \n",
      "model to malfunction and generate incorrect or unsafe outputs, which can have significant \n",
      "impacts. For example, manipulating the inputs of a self-driving car may fool the model to \n",
      "perceive a red light as a green one, adversely impacting road safety. \n",
      "AI assuranceA combination of frameworks, policies, processes and controls that measure, evaluate and \n",
      "promote safe, reliable and trustworthy AI. AI assurance schemes may include conformity, \n",
      "impact and risk assessments, AI audits , certifications, testing and evaluation, and \n",
      "compliance with relevant standards.\n",
      "AI auditA review and assessment of an AI system to ensure it operates as intended and complies \n",
      "with relevant laws, regulations and standards. An AI audit can help identify and map risks \n",
      "and offer mitigation strategies.\n",
      "AI governanceA system of laws, policies, frameworks, practices and processes at international, \n",
      "national and organizational levels. AI governance helps various stakeholders implement, \n",
      "manage, oversee and regulate the development, deployment and use of AI technology. \n",
      "It also helps manage associated risks to ensure AI aligns with stakeholders' objectives, \n",
      "is developed and used responsibly and ethically, and complies with applicable legal \n",
      "and regulatory requirements.\n",
      "AlgorithmA procedure or set of instructions and rules designed to perform a specific task or solve \n",
      "a particular problem using a computer. \n",
      "Artificial general \n",
      "intelligenceAI that is considered to have human-level intelligence and strong generalization  \n",
      "capability to achieve goals and carry out a broad range of tasks in different contexts and \n",
      "environments. AGI remains a theoretical field of research. It is contrasted with \"narrow\" \n",
      "AI, which is used for specific tasks or problems. \n",
      " →Acronym: AGIKey Terms for AI Governance 3A B C D E F G H I L M N O P R S T U V W Key terms\n",
      "TERM DEFINITION\n",
      "Artificial intelligenceArtificial intelligence is a broad term used to describe an engineered system that uses \n",
      "various computational techniques to perform or automate tasks. This may include \n",
      "techniques, such as machine learning , in which machines learn from experience, adjusting \n",
      "to new input data  and potentially performing tasks previously done by humans. More \n",
      "specifically, it is a field of computer science dedicated to simulating intelligent behavior \n",
      "in computers. It may include automated decision-making . \n",
      " →Acronym: AI\n",
      "Automated \n",
      "decision-makingThe process of making a decision by technological means without human involvement, \n",
      "either in whole or in part. \n",
      "BiasThere are several types of bias within the AI field. Computational bias or machine bias is \n",
      "a systematic error or deviation from the true value of a prediction that originates from a \n",
      "model's assumptions or the data itself (see also input data ). \n",
      "Cognitive bias refers to inaccurate individual judgment or distorted thinking, while societal \n",
      "bias leads to systemic prejudice, favoritism and/or discrimination in favor of or against an \n",
      "individual or group. Either or both may permeate the model or the system in numerous \n",
      "ways, such as through selection bias, i.e. biases in selecting data for model training. Bias \n",
      "can impact outcomes and pose a risk to individual rights and liberties. \n",
      "Bootstrap aggregatingA machine learning  method that aggregates multiple versions of a model (see also \n",
      "machine learning model ) trained on random subsets of a dataset. This method aims \n",
      "to make a model more stable and accurate. \n",
      " →Sometimes referred to as bagging.\n",
      "ChatbotA form of AI designed to simulate human-like conversations and interactions that \n",
      "uses natural language processing  and deep learning  to understand and respond to \n",
      "text or speech. \n",
      "Classification modelA type of model (see also machine learning model ) used in machine learning  that \n",
      "is designed to take input data and sort it into different categories or classes.\n",
      " →Sometimes referred to as classifiers.\n",
      "ClusteringAn unsupervised machine learning  method in which patterns in the data are identified and \n",
      "evaluated, and data points are grouped accordingly into clusters based on their similarity. \n",
      " →Sometimes referred to as clustering algorithms.\n",
      "ComputeThe processing resources that are available to a computer system. This includes hardware \n",
      "components such as the central processing unit or graphics processing unit. Compute is \n",
      "essential for memory, storage, processing data, running applications, rendering graphics \n",
      "for visual media and powering cloud computing, among others. \n",
      "Computer visionA field of AI that uses computers to process and analyze images, videos and other \n",
      "visual inputs. Common applications of computer vision include facial recognition, \n",
      "object recognition and medical imaging. Key Terms for AI Governance 4A B C D E F G H I L M N O P R S T U V W Key terms\n",
      "TERM DEFINITION\n",
      "Conformity assessmentAn analysis, often performed by an entity independent of a model developer, on an AI \n",
      "system to determine whether requirements, such as establishing a risk management \n",
      "system, data governance, record-keeping, transparency  and cybersecurity practices \n",
      "have been met. \n",
      "ContestabilityThe principle of ensuring AI systems and their decision-making processes can be \n",
      "questioned or challenged by humans. This ability to contest or challenge the outcomes, \n",
      "outputs and actions of AI systems depends on transparency  and helps promote \n",
      "accountability  within AI governance . \n",
      " →Also called redress.\n",
      "CorpusA large collection of texts or data that a computer uses to find patterns, make predictions \n",
      "or generate specific outcomes. The corpus may include structured or unstructured data \n",
      "and cover a specific topic or a variety of topics. \n",
      "Data leakAn accidental exposure of sensitive, personal, confidential or proprietary data. This can \n",
      "be a result of poor security defenses, human error, storage misconfigurations or a lack of \n",
      "robust policies around internal and external data sharing practices. Unlike a data breach, \n",
      "a data leak is unintentional and not done in bad faith.\n",
      "Data poisoningAn adversarial attack in which a malicious user injects false data into a model to \n",
      "manipulate the training process, thereby corrupting the learning algorithm. The goal \n",
      "is to introduce intentional errors into the training dataset, leading to compromised \n",
      "performance and resulting in undesired, misleading or harmful outputs. \n",
      "Data provenanceA process that tracks and logs the history and origin of records in a dataset, encompassing \n",
      "the entire life cycle from its creation and collection to its transformation to its current \n",
      "state. It includes information about sources, processes, actors and methods used to \n",
      "ensure data integrity and quality. Data provenance is essential for data transparency \n",
      "and governance, and it promotes better understanding of the data and eventually the \n",
      "entire AI system.\n",
      "Data qualityThe measure of how well a dataset meets the specific requirements and expectations \n",
      "for its intended use. Data quality directly impacts the quality of AI outputs and the \n",
      "performance of an AI system. High-quality data is accurate, complete, valid, consistent, \n",
      "timely and fit for purpose.\n",
      "Decision treeA type of supervised learning  model used in machine learning (see also machine \n",
      "learning model ) that represents decisions and their potential consequences in a \n",
      "branching structure. \n",
      "Deep learningA subfield of AI and machine learning  that uses artificial neural networks . Deep learning \n",
      "is especially useful in fields where raw data needs to be processed, like image recognition, \n",
      "natural language processing  and speech recognition. Key Terms for AI Governance 5A B C D E F G H I L M N O P R S T U V W Key terms\n",
      "TERM DEFINITION\n",
      "DeepfakesAudio or visual content that has been altered or manipulated using artificial intelligence  \n",
      "techniques. Deepfakes can be used to spread misinformation  and disinformation . \n",
      "Diffusion modelA generative model used in image generation that works by iteratively refining a noise \n",
      "signal to transform it into a realistic image when prompted.\n",
      "Discriminative modelA type of model (see also machine learning model ) used in machine learning  that directly \n",
      "maps input features to class labels and analyzes for patterns that can help distinguish \n",
      "between different classes. It is often used for text classification tasks, like identifying the \n",
      "language of a piece of text or detecting spam. Examples are traditional neural networks , \n",
      "decision trees  and random forest . \n",
      "DisinformationAudio or visual content that is intentionally manipulated or created to cause \n",
      "harm. Disinformation can spread through deepfakes  created by those who have \n",
      "malicious intentions. \n",
      "EntropyThe measure of unpredictability or randomness in a set of data used in machine learning . \n",
      "A higher entropy signifies greater uncertainty in predicting outcomes. \n",
      "Expert systemA form of rules-based AI that draws inferences from a knowledge base provided by \n",
      "human experts to replicate their decision-making abilities within a specific field, like \n",
      "medical diagnoses. \n",
      "ExplainabilityThe ability to describe or provide sufficient information about how an AI system generates \n",
      "a specific output or arrives at a decision in a specific context. Explainability is important in \n",
      "maintaining transparency and trust in AI.\n",
      "Exploratory data analysisData discovery process techniques that take place before training a machine learning \n",
      "model  to gain preliminary insights into a dataset, such as identifying patterns, outliers \n",
      "and anomalies and finding relationships among variables .\n",
      "Fairness1An attribute of an AI system that prioritizes relatively equal treatment of individuals or \n",
      "groups in its decisions and actions in a consistent, accurate and measurable manner. \n",
      "Every model must identify the appropriate standard of fairness that best applies, but most \n",
      "often it means the AI system's decisions should not adversely impact, whether directly or \n",
      "disparately, sensitive attributes like race, gender or religion. \n",
      "Federated learningA machine learning  method that allows models (see also machine learning model ) to be \n",
      "trained on the local data of multiple edge devices. Only the updates of the local model, not \n",
      "the training data itself, are sent to a central location where they are aggregated to improve \n",
      "the global model — a process that is iterated until the global model is fully trained. This \n",
      "process enables better privacy and security controls for the individual user data. Key Terms for AI Governance 6A B C D E F G H I L M N O P R S T U V W Key terms\n",
      "TERM DEFINITION\n",
      "Fine-tuningThe process of taking a pretrained deep learning model and training it further for a \n",
      "specialized task through supervised learning . It involves taking a foundation model  that \n",
      "has already learned general patterns from a large dataset and training it for a specific task \n",
      "using a much smaller and labeled dataset. \n",
      "Foundation modelA large-scale model that has been trained on extensive and diverse datasets to \n",
      "enable broad capabilities, such as language (see also large language model ), vision, \n",
      "robotics, reasoning, search or human interaction, that can function as the base for \n",
      "use-specific applications. \n",
      " →Also called general purpose AI model and frontier AI. \n",
      "GeneralizationThe ability of a model (see also machine learning model ) to understand the underlying \n",
      "patterns and trends in its training data and apply what it has learned to make predictions \n",
      "or decisions about new, unseen data. \n",
      "Generative AIA field of AI that uses deep learning  trained on large datasets to create content, such as \n",
      "written text, code, images, music, simulations and videos, in response to user prompts . \n",
      "Unlike discriminative models , generative AI makes predictions on existing data rather \n",
      "than new data. \n",
      "Greedy algorithmsA type of algorithm  that makes the optimal choice to achieve an immediate objective at a \n",
      "particular step or decision point based on the available information and without regard for \n",
      "the long-term optimal solution. \n",
      "Ground truthThe absolute or objectively known state of a dataset against which the quality of an AI \n",
      "system can be evaluated. It serves as the real-world reference against which the outputs \n",
      "are measured for accuracy  and reliability.\n",
      "HallucinationsInstances in which generative AI  models create seemingly plausible but factually incorrect \n",
      "outputs under the appearance of fact. \n",
      " →Also called confabulations. \n",
      "Human-centric AIAn approach to AI design, development, deployment and use that prioritizes human \n",
      "well-being, autonomy, values and needs. The goal is to develop AI systems that amplify \n",
      "and augment human abilities rather than undermine them.\n",
      "Human-in-the-loopA design paradigm that incorporates human oversight, intervention, interaction or control \n",
      "over the operation and decision-making processes of an AI system. \n",
      " →Acronym: HITL\n",
      "Impact assessmentAn evaluation process designed to identify, understand, document and mitigate \n",
      "the potential ethical, legal, economic and societal implications of an AI system in \n",
      "a specific use case.Key Terms for AI Governance 7A B C D E F G H I L M N O P R S T U V W Key terms\n",
      "TERM DEFINITION\n",
      "InferenceA type of machine learning  process in which a trained model (see also machine learning \n",
      "model ) is used to make predictions or decisions based on input data . \n",
      "Input dataData provided to or directly acquired by a learning algorithm  or model (see also machine \n",
      "learning model ) for the purpose of producing an output. It forms the basis for machine \n",
      "learning models to learn, make predictions and carry out tasks. \n",
      "InterpretabilityThe ability to explain or present a model's reasoning in human-understandable \n",
      "terms. Unlike explainability , which provides an explanation after a decision is made, \n",
      "interpretability emphasizes designing models that inherently facilitate understanding \n",
      "through their structure, features or algorithms. Interpretable models are domain-specific \n",
      "and require significant domain expertise to develop.\n",
      "Large language modelA form of AI that utilizes deep learning  algorithms to create models (see also machine \n",
      "learning model , foundation model  and fine-tuning ) pretrained on massive text datasets \n",
      "for the general purpose of analyzing and learning patterns and relationships among \n",
      "characters, words and phrases to perform text-based tasks. There are generally two \n",
      "types of LLMs: generative models that make text predictions based on the probabilities of \n",
      "word sequences learned from its training data (see also generative AI ) and discriminative \n",
      "models that make classification predictions based on probabilities of data features and \n",
      "weights learned from its training data (see also discriminative model ). The word large \n",
      "generally refers to the model's capacity measured by the number of parameters and to the \n",
      "enormous datasets it is trained on. \n",
      " →Acronym: LLM\n",
      "Machine learningA subfield of AI involving algorithms that iteratively learn from and then make decisions, \n",
      "recommendations, inferences  or predictions based on input data . These algorithms build \n",
      "a model from training data to perform a specific task on new data without being explicitly \n",
      "programmed to do so. \n",
      "Machine learning implements various algorithms that learn and improve by experience \n",
      "in a problem-solving process that includes data collection and preparation, feature \n",
      "engineering, training, testing and validation. Companies and government agencies deploy \n",
      "machine learning algorithms for tasks such as fraud detection, recommender systems, \n",
      "customer inquiries, health care, and transportation and logistics. \n",
      " →Acronym: ML\n",
      "Machine learning modelA learned representation of underlying patterns and relationships in data, created by \n",
      "applying an AI algorithm to a training dataset. The model can then be used to make \n",
      "predictions or perform tasks on new, unseen data. \n",
      "MisinformationFalse audio or visual content that is unintentionally misleading. It can be spread through \n",
      "deepfakes  created by those who lack intent to cause harm. \n",
      "Model cardA brief document that discloses information about an AI model, like explanations about \n",
      "intended use, performance metrics and benchmarked evaluation in various conditions, \n",
      "such as across different cultures, demographics or race (see also system cards ).Key Terms for AI Governance 8A B C D E F G H I L M N O P R S T U V W Key terms\n",
      "TERM DEFINITION\n",
      "Multimodal modelsA type of model used in machine learning  (see also machine learning model ) that can \n",
      "process more than one type of input or output data, or \"modality,\" at the same time. \n",
      "For example, a multimodal model can take both an image and text caption as input and \n",
      "then produce a unimodal output in the form of a score indicating how well the text caption \n",
      "describes the image. These models are highly versatile and useful in a variety of tasks, \n",
      "like image captioning and speech recognition. \n",
      "Natural language \n",
      "processingA subfield of AI that helps computers understand, interpret and apply human language by \n",
      "transforming information into content. It enables machines to translate languages, read \n",
      "text or spoken language, interpret its meaning, measure sentiment, and determine which \n",
      "parts are important for understanding. \n",
      "Neural networksA type of model (see also machine learning model ) used in deep learning  that mimics the \n",
      "way neurons in the human brain interact with multiple processing layers, including at least \n",
      "one hidden layer. This layered approach enables machine-based neural networks to model \n",
      "complex nonlinear relationships and patterns within data. Artificial neural networks have a \n",
      "range of applications, such as image recognition and medical diagnoses. \n",
      "Open-source softwareA decentralized development model that provides the public with free and open access \n",
      "to source code, which can then be viewed, modified and redistributed according to the \n",
      "terms of its respective license. The goal is to promote innovation, transparency, shared \n",
      "collaboration and learning among researchers and technical experts. \n",
      "OverfittingA concept in machine learning  that involves a model (see also machine learning model ) \n",
      "becoming too specific to the training data and unable to generalize to unseen data, \n",
      "which means it can fail to make accurate predictions on new datasets. \n",
      "OversightThe process of effectively monitoring and supervising an AI system to minimize risks, \n",
      "ensure regulatory compliance and uphold responsible practices. Oversight is important for \n",
      "effective AI governance , and mechanisms may include certification processes, conformity \n",
      "assessments and regulatory authorities responsible for enforcement. \n",
      "ParametersThe internal variables an algorithmic model learns from the training data. They are values \n",
      "the model adjusts to during the training process so it can make predictions on new data. \n",
      "Parameters are specific to the architecture of the model. For example, in neural networks , \n",
      "parameters are the weights of each neuron in the network. \n",
      "Post processingSteps performed after a machine learning model  has been run to adjust its output. This \n",
      "can include adjusting a model's outputs or using a holdout dataset — data not used in the \n",
      "training of the model — to create a function run on the model's predictions to improve \n",
      "fairness or meet business requirements. \n",
      "PreprocessingSteps taken to prepare data for training a machine learning model , which can include \n",
      "cleaning the data, handling missing values, normalizing the data, performing feature \n",
      "extraction and encoding categorical variables. Data preprocessing can play a crucial role \n",
      "in improving data quality, mitigating bias, addressing algorithmic fairness concerns and \n",
      "enhancing the performance and reliability of machine learning algorithms. Key Terms for AI Governance 9A B C D E F G H I L M N O P R S T U V W Key terms\n",
      "TERM DEFINITION\n",
      "Prompt An input or instruction provided to an AI model or system to generate an output. \n",
      "Prompt engineeringPrompt engineering is the deliberate process of structuring a prompt or series of prompts \n",
      "to influence model behavior to generate more desirable outputs. \n",
      "Random forestA supervised machine learning (see also supervised learning ) algorithm that builds \n",
      "multiple decision trees  and merges them to get a more accurate and stable prediction. \n",
      "Each decision tree is built with a random subset of the training data (see also bootstrap \n",
      "aggregating ), hence the name random forest. Random forests are helpful to use with \n",
      "datasets that are missing values or are very complex. \n",
      "Red teamingThe process of testing the safety, security and performance of an AI system through an \n",
      "adversarial lens, typically through the simulation of adversarial attacks on the model \n",
      "to evaluate it against certain benchmarks, jailbreak it and try to make it behave in \n",
      "unintended or inappropriate ways. Red teaming reveals security risks, model flaws, biases, \n",
      "misinformation and other harms, and the results of such testing are passed along to the \n",
      "model developers for evaluation and remediation. Developers use red teaming to improve \n",
      "a model before and after releasing it to the public.\n",
      "Reinforcement learningA machine learning  method that trains a model to optimize its actions within a given \n",
      "environment to achieve a specific goal, guided by feedback mechanisms of rewards and \n",
      "penalties. This training is often conducted through trial-and-error interactions or simulated \n",
      "experiences that do not require external data. For example, an algorithm can be trained \n",
      "to earn a high score in a video game by having its efforts evaluated and rated according to \n",
      "success toward the goal. \n",
      "Reinforcement learning \n",
      "with human feedbackThe process of combining the technique of reinforcement learning  with human feedback \n",
      "during the training process. Human feedback is provided on the model's output, often \n",
      "by comparing different outputs for the same prompt  and indicating which output aligns \n",
      "better with human preferences. In reinforcement learning, the model learns by receiving \n",
      "rewards or penalties. Combining this with human feedback provides an additional source \n",
      "of rewards and penalties and helps align the AI's behavior with human preferences \n",
      "and values. \n",
      " →Acronym: RLHF\n",
      "ReliabilityAn attribute of an AI system that ensures it behaves as expected and performs its intended \n",
      "function consistently and accurately, even with new data that it has not been trained on. \n",
      "RoboticsA multidisciplinary field that encompasses the design, construction, operation and \n",
      "programming of robots. Robotics allow AI systems and software to interact with the \n",
      "physical world. \n",
      "RobustnessAn attribute of an AI system that signifies the system's ability to be resilient to, overcome \n",
      "and withstand security attacks. Robustness ensures the system's functionality, \n",
      "performance and accuracy  in a variety of environments and circumstances, even when \n",
      "faced with changed inputs or security attacks. Key Terms for AI Governance 10A B C D E F G H I L M N O P R S T U V W Key terms\n",
      "TERM DEFINITION\n",
      "SafetyA broad term, which may refer to designing, developing and deploying AI systems that \n",
      "minimize AI harms from misinformation, disinformation, deepfakes, hallucinations and \n",
      "other unintended behaviors. It may also refer to mitigating and managing malicious use or \n",
      "rogue behavior. Safety also encompasses the prevention of existential or unexpected risks \n",
      "that may arise from advanced AI capabilities reflected in foundation models . \n",
      "Semi-supervised learningA subset of machine learning  that combines both supervised learning  and unsupervised \n",
      "learning  by training the model on a large amount of unlabeled data and a small amount \n",
      "of labeled data. This avoids the challenges of finding large amounts of labeled data for \n",
      "training the model. Generative AI  commonly relies on semi-supervised learning. \n",
      "Small language modelsA smaller version of their better-known and larger counterparts, large language models . \n",
      "Small is a reference to the size of the models. They have fewer parameters  and require a \n",
      "much smaller training dataset, optimizing them for efficiency and better suiting them for \n",
      "deployment in environments with limited computational resources or for applications that \n",
      "require faster training and inference  time.\n",
      "Supervised learningA subset of machine learning  in which the model (see also machine learning model ) is \n",
      "trained on labeled input data  with known desired outputs. These two groups of data \n",
      "are sometimes called predictors and targets or independent and dependent variables \n",
      "respectively. This type of learning is useful for classification or regression. The former \n",
      "refers to training an AI to group data into specific categories and the latter refers to \n",
      "making predictions by understanding the relationship between two variables. \n",
      "Synthetic dataData generated by a system or model (see also machine learning model ) that generally \n",
      "resembles the structure and statistical properties of real data but without any real-world, \n",
      "identifying information. It is often used for testing or training machine-learning models, \n",
      "particularly in cases with limited, unavailable or too sensitive real-world data. \n",
      "System cardSimilar to a model card , a system card is a brief document that discloses information about \n",
      "how various AI models work together within a network of AI systems, promoting greater \n",
      "explainability of the overall system.\n",
      "T esting dataThe dataset used to test and evaluate a trained model (see also machine learning model ). \n",
      "It is used to assess the performance of the model with new data at the very end of the \n",
      "initial model development process and for future upgrades or variations to the model. \n",
      "Training dataThe dataset used to train a model (see also machine learning model ) so it can accurately \n",
      "predict outcomes, find patterns or identify structures within the training data. \n",
      "Transfer learning modelA type of model (see also machine learning model ) used in machine learning  in which an \n",
      "algorithm learns to perform one task, such as recognizing cats, and then uses that learned \n",
      "knowledge as a basis when learning a different but related task, such as recognizing dogs. Key Terms for AI Governance 11A B C D E F G H I L M N O P R S T U V W Key terms\n",
      "TERM DEFINITION\n",
      "Transformer modelA neural network  architecture that learns context and maintains relationships between \n",
      "sequence data, such as words in a sentence. It does so by leveraging the technique of \n",
      "attention, i.e., focusing on the most important and relevant parts of the input sequence. \n",
      "This helps to improve model accuracy. For example, in language learning tasks, by \n",
      "attending to the surrounding words, the model can comprehend the meaning of a \n",
      "word in the context of the whole sentence. \n",
      "Transparency1A broad term that implies openness, comprehensibility and accountability  in the way AI \n",
      "algorithms function and make decisions. However, the specific meaning of transparency \n",
      "may vary depending on context. \n",
      "May refer to the extent to which information regarding an AI system is made available to \n",
      "stakeholders, including disclosing if AI is used through techniques like watermarking , and \n",
      "explaining how the model works through model or system cards for example. \n",
      "It also refers to maintenance of technical and nontechnical documentation across the \n",
      "AI life cycle to keep track of processes and decision-making, which can also assist with \n",
      "auditability of the AI system. \n",
      "In the open-source context , transparency may refer to making the source code \n",
      "publicly accessible. \n",
      "Trustworthy AIIn most cases, this term is used interchangeably with the terms responsible AI and ethical \n",
      "AI, which all refer to principle-based AI development and AI governance , including the \n",
      "principles of security, safety, transparency , explainability , accountability , privacy and \n",
      "nondiscrimination/nonbias (see also bias), among others. \n",
      "Turing testA test of a machine's ability to exhibit intelligent behavior equivalent to or indistinguishable \n",
      "from that of a human. Alan Turing (1912-1954) originally thought of the test to be an AI's \n",
      "ability to converse through a written text, such that a human reader would not be able to \n",
      "tell a computer-generated response from that of a human. \n",
      "UnderfittingA concept in machine learning  in which a model (see also machine learning model ) fails to \n",
      "fully capture the complexity of the training data. This may result in poor predictive ability \n",
      "and inaccurate outputs. Factors leading to underfitting may include having too few model \n",
      "parameters, having too high a regularization rate, or using an inappropriate or insufficient \n",
      "set of features in the training data. \n",
      "Unsupervised learningA subset of machine learning  in which the model is trained by looking for patterns in an \n",
      "unclassified dataset with minimal human supervision. The AI is provided with preexisting \n",
      "unlabeled datasets and then analyzes those datasets for patterns. This type of learning \n",
      "is useful for training an AI for techniques such as clustering  data, outlier detection, \n",
      "dimensionality reduction, feature learning and principal component analysis.\n",
      "Validation dataA subset of the dataset used to assess the performance of the model (see also machine \n",
      "learning model ) during the training phase. Validation data is used for fine-tuning  the \n",
      "parameters of a model and preventing overfitting before the final evaluation using the \n",
      "test dataset. Key Terms for AI Governance 12A B C D E F G H I L M N O P R S T U V W Key terms\n",
      "TERM DEFINITION\n",
      "VariablesIn the context of machine learning , a variable is a measurable attribute, characteristic \n",
      "or unit that can take on different values. Variables can be numerical/quantitative or \n",
      "categorical/qualitative. \n",
      " →Also called features. \n",
      "VarianceA statistical measure that reflects how far a set of numbers are spread out from their \n",
      "average value in a dataset. A high variance indicates the data points are spread widely \n",
      "around the mean. A low variance indicates the data points are close to the mean. In \n",
      "machine learning, higher variance can lead to overfitting . The trade-off between variance \n",
      "and bias is a fundamental concept in machine learning. Model complexity tends to reduce \n",
      "bias but increase variance. Decreasing complexity reduces variance but increases bias. \n",
      "WatermarkingThe process of embedding subtle or visually imperceptible patterns in AI-generated \n",
      "content or metadata that can only be detected by computers. Watermarking helps with \n",
      "the detection and labelling of AI generated content, promoting transparency.\n",
      "Notes\n",
      "1 Different definition than IAPP privacy training glossary .More resources\n",
      " →AI Governance Center\n",
      " →AI topic page →AI Body of KnowledgeKey Terms for AI Governance 13\n",
      "Find the latest version at iapp.org/resourcesUpdated July 2024.IAPP disclaims all warranties, expressed or implied, with respect to the contents of this material, including any warranties \n",
      "of accuracy, merchantability, or fitness for a particular purpose. Nothing herein should be construed as legal advice. \n",
      "© 2024 IAPP. All rights reserved.Accountability  .....................  1\n",
      "Accuracy   .........................  1\n",
      "Active learning  ....................  2\n",
      "Adaptive learning   .................  2\n",
      "Adversarial attack   .................  2\n",
      "AI assurance  ......................  2\n",
      "AI audit   ..........................  2\n",
      "AI governance   ....................  2\n",
      "Algorithm   ........................  2\n",
      "Artificial general intelligence   . . . . . . . .  2\n",
      "Artificial intelligence   ...............  3\n",
      "Automated decision-making   ........  3\n",
      "Bias   .............................  3\n",
      "Bootstrap aggregating   .............  3\n",
      "Chatbot  ..........................  3\n",
      "Classification model   ...............  3\n",
      "Clustering   ........................  3\n",
      "Compute  .........................  3\n",
      "Computer vision   ..................  3\n",
      "Conformity assessment   ............  4\n",
      "Contestability  .....................  4\n",
      "Corpus  ...........................  4\n",
      "Data leak  .........................  4\n",
      "Data poisoning  ....................  4\n",
      "Data provenance  ..................  4\n",
      "Data quality   ......................  4\n",
      "Decision tree   .....................  4\n",
      "Deep learning  .....................  4\n",
      "Deepfakes  ........................  5\n",
      "Diffusion model  ...................  5\n",
      "Discriminative model   ..............  5Disinformation  ....................  5\n",
      "Entropy   ..........................  5\n",
      "Expert system   ....................  5\n",
      "Explainability   .....................  5\n",
      "Exploratory data analysis  ...........  5\n",
      "Fairness  ..........................  5\n",
      "Federated learning   ................  5\n",
      "Fine-tuning   . . . . . . . . . . . . . . . . . . . . . . .  6\n",
      "Foundation model  .................  6\n",
      "Generalization   ....................  6\n",
      "Generative AI   .....................  6\n",
      "Greedy algorithms  .................  6\n",
      "Ground truth   .....................  6\n",
      "Hallucinations   ....................  6\n",
      "Human-centric AI  ..................  6\n",
      "Human-in-the-loop   ................  6\n",
      "Impact assessment  ................  6\n",
      "Inference  .........................  7\n",
      "Input data  ........................  7\n",
      "Interpretability  ....................  7\n",
      "Large language model   .............  7\n",
      "Machine learning  ..................  7\n",
      "Machine learning model  ............  7\n",
      "Misinformation   ...................  7\n",
      "Model card   .......................  7\n",
      "Multimodal models  ................  8\n",
      "Natural language processing  ........  8\n",
      "Neural networks   ..................  8\n",
      "Open-source software   .............  8\n",
      "Overfitting  ........................  8\n",
      "Oversight   ........................  8Parameters  .......................  8\n",
      "Post processing   ...................  8\n",
      "Preprocessing   ....................  8\n",
      "Prompt   ..........................  9\n",
      "Prompt engineering   ...............  9\n",
      "Random forest  ....................  9\n",
      "Red teaming  ......................  9\n",
      "Reinforcement learning   ............  9\n",
      "Reinforcement learning with \n",
      "human feedback   ..................  9\n",
      "Reliability  .........................  9\n",
      "Robotics   .........................  9\n",
      "Robustness  .......................  9\n",
      "Safety  ...........................  10\n",
      "Semi-supervised learning  ..........  10\n",
      "Small language models  ............  10\n",
      "Supervised learning   ..............  10\n",
      "Synthetic data   ...................  10\n",
      "System card   .....................  10\n",
      "Testing data   .....................  10\n",
      "Training data   ....................  10\n",
      "Transfer learning model  ...........  10\n",
      "Transformer model  ...............  11\n",
      "Transparency  ....................  11\n",
      "Trustworthy AI  ...................  11\n",
      "Turing test  .......................  11\n",
      "Underfitting   .....................  11\n",
      "Unsupervised learning   . . . . . . . . . . . .  11\n",
      "Validation data  ...................  11\n",
      "Variables  ........................  12\n",
      "Variance   ........................  12\n",
      "Watermarking   ...................  12Key terms\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# Example usage:\n",
    "pdf_path = \"/kaggle/input/ai-gov-term/key_terms_for_ai_governance.pdf\"  # Replace with the correct path to your PDF\n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n",
    "print(pdf_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T09:35:35.592320Z",
     "iopub.status.busy": "2024-08-12T09:35:35.591859Z",
     "iopub.status.idle": "2024-08-12T09:36:21.296534Z",
     "shell.execute_reply": "2024-08-12T09:36:21.295128Z",
     "shell.execute_reply.started": "2024-08-12T09:35:35.592281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.2.12)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.29)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.99)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (4.12.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain) (2.4)\n",
      "Requirement already satisfied: langchain_community in /opt/conda/lib/python3.10/site-packages (0.2.11)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (3.9.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.12 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.2.12)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.2.29)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.1.99)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.12->langchain_community) (0.2.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.12->langchain_community) (2.5.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain_community) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.12->langchain_community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.12->langchain_community) (2.14.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: openai in /opt/conda/lib/python3.10/site-packages (1.40.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (2.5.3)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/conda/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain_community\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T09:36:34.689451Z",
     "iopub.status.busy": "2024-08-12T09:36:34.689023Z",
     "iopub.status.idle": "2024-08-12T09:36:34.695491Z",
     "shell.execute_reply": "2024-08-12T09:36:34.694155Z",
     "shell.execute_reply.started": "2024-08-12T09:36:34.689415Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T09:48:52.337052Z",
     "iopub.status.busy": "2024-08-12T09:48:52.336587Z",
     "iopub.status.idle": "2024-08-12T09:49:08.589831Z",
     "shell.execute_reply": "2024-08-12T09:49:08.588451Z",
     "shell.execute_reply.started": "2024-08-12T09:48:52.337018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.1.21-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.29 in /opt/conda/lib/python3.10/site-packages (from langchain-openai) (0.2.29)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /opt/conda/lib/python3.10/site-packages (from langchain-openai) (1.40.3)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.29->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.29->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.29->langchain-openai) (0.1.99)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.29->langchain-openai) (24.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.29->langchain-openai) (2.5.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.29->langchain-openai) (8.2.3)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.29->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.66.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.29->langchain-openai) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.29->langchain-openai) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.29->langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.29->langchain-openai) (2.14.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (1.26.18)\n",
      "Downloading langchain_openai-0.1.21-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.8/49.8 kB\u001b[0m \u001b[31m655.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tiktoken, langchain-openai\n",
      "Successfully installed langchain-openai-0.1.21 tiktoken-0.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T10:08:00.407832Z",
     "iopub.status.busy": "2024-08-12T10:08:00.407326Z",
     "iopub.status.idle": "2024-08-12T10:08:04.652852Z",
     "shell.execute_reply": "2024-08-12T10:08:04.651436Z",
     "shell.execute_reply.started": "2024-08-12T10:08:00.407797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCQ 1:\n",
      "**Multiple-Choice Question:**\n",
      "\n",
      "**What is the primary purpose of the glossary update to the \"Key Terms for AI Governance\" released by IAPP in October 2023?**\n",
      "\n",
      "A) To provide a single, comprehensive definition for \"artificial intelligence.\"\n",
      "\n",
      "B) To introduce new terms and modify existing terms in AI governance based on expert feedback and various referenced materials.\n",
      "\n",
      "C) To replace the IAPP Glossary of Privacy Terms.\n",
      "\n",
      "D) To explain the cinematic and creative applications of AI like HAL 9000 and Midjourney.\n",
      "\n",
      "**Answer:** B) To introduce new terms and modify existing terms in AI governance based on expert feedback and various referenced materials.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Define your prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"Generate a multiple-choice question from the following text: {text}\"\n",
    ")\n",
    "\n",
    "# Initialize the LLM with the chat model\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    api_key=\"API_KEY\"\n",
    "\n",
    "# Create the LLMChain\n",
    "mcq_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# Function to generate MCQs from text\n",
    "def generate_mcqs_from_text(text, num_questions=10):\n",
    "    paragraphs = text.split(\"\\n\\n\")\n",
    "    mcqs = []\n",
    "    \n",
    "    for i in range(min(num_questions, len(paragraphs))):\n",
    "        question = mcq_chain.run({\"text\": paragraphs[i]})\n",
    "        mcqs.append(question)\n",
    "    \n",
    "    return mcqs\n",
    "\n",
    "# Example usage\n",
    "pdf_path = \"/kaggle/input/ai-gov-term/key_terms_for_ai_governance.pdf\"\n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n",
    "mcqs = generate_mcqs_from_text(pdf_text, num_questions=10)\n",
    "\n",
    "# Print the generated MCQs\n",
    "for idx, mcq in enumerate(mcqs, 1):\n",
    "    print(f\"MCQ {idx}:\")\n",
    "    print(mcq)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T10:10:41.320571Z",
     "iopub.status.busy": "2024-08-12T10:10:41.320169Z",
     "iopub.status.idle": "2024-08-12T10:10:45.641893Z",
     "shell.execute_reply": "2024-08-12T10:10:45.640610Z",
     "shell.execute_reply.started": "2024-08-12T10:10:41.320541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCQ 1:\n",
      "### Multiple-Choice Question:\n",
      "\n",
      "**What is the primary purpose of the updated version of IAPP's Key Terms for AI Governance released in July 2024?**\n",
      "\n",
      "A) To provide definitions of common AI terms used in the cinematic industry.\n",
      "\n",
      "B) To ensure a common lexicon and shared understanding of terms and phrases used in AI governance among business, technology, and government professionals.\n",
      "\n",
      "C) To offer a detailed review of AI's impact on email autocorrect and mobile maps.\n",
      "\n",
      "D) To describe the differences between various types of bias in AI systems.\n",
      "\n",
      "**Answer: B) To ensure a common lexicon and shared understanding of terms and phrases used in AI governance among business, technology, and government professionals.**\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Define your prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"Generate a multiple-choice question from the following text: {text}\"\n",
    ")\n",
    "\n",
    "# Initialize the LLM with the chat model\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "     api_key=\"API_KEY\"\n",
    "\n",
    "# Create the LLMChain\n",
    "mcq_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# Function to generate MCQs from text\n",
    "def generate_mcqs_from_text(text, num_questions=10):\n",
    "    paragraphs = text.split(\"\\n\\n\")\n",
    "    mcqs = []\n",
    "    \n",
    "    for i in range(min(num_questions, len(paragraphs))):\n",
    "        # Extract text for each prompt\n",
    "        paragraph_text = paragraphs[i]\n",
    "        \n",
    "        # Generate MCQ for each paragraph\n",
    "        question = mcq_chain.run({\"text\": paragraph_text})\n",
    "        mcqs.append(question)\n",
    "    \n",
    "    return mcqs\n",
    "\n",
    "# Example usage\n",
    "pdf_path = \"/kaggle/input/ai-gov-term/key_terms_for_ai_governance.pdf\"\n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n",
    "mcqs = generate_mcqs_from_text(pdf_text, num_questions=10)\n",
    "\n",
    "# Print the generated MCQs\n",
    "for idx, mcq in enumerate(mcqs, 1):\n",
    "    print(f\"MCQ {idx}:\")\n",
    "    print(mcq)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T10:15:58.354420Z",
     "iopub.status.busy": "2024-08-12T10:15:58.354016Z",
     "iopub.status.idle": "2024-08-12T10:16:04.073356Z",
     "shell.execute_reply": "2024-08-12T10:16:04.071840Z",
     "shell.execute_reply.started": "2024-08-12T10:15:58.354383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total paragraphs: 1\n",
      "Processing paragraph 1: Key Terms for AI Governance 1The field of AI is rapidly evolving across different sectors and disparate industries, leaving business, technology and \n",
      "government professionals without a common lexicon and shared understanding of terms and phrases used in AI \n",
      "governance. Even a search to define \"artificial intelligence\" returns a range of definitions and examples. From the \n",
      "cinematic, like HAL 9000 from \"2001: A Space Odyssey,\" to the creative, like Midjourney and DALL-E generative art, \n",
      "to the common, like email autocorrect and mobile maps, the use cases and applications of AI continue to grow and \n",
      "expand into all aspects of life.\n",
      "This glossary is an update to the October 2023  release of IAPP's Key Terms for AI Governance. The updated \n",
      "version has been developed with reference to various materials and with valuable feedback from top experts \n",
      "in AI governance. It includes new terms and modifications to existing terms.\n",
      "The original glossary from June 2023 was developed with reference to numerous materials and designed to provide \n",
      "succinct, but nuanced, definitions and explanations for some of the most common terms related to AI today. \n",
      "The same methodology has been retained for the new updates. The explanations aim to present both policy and \n",
      "technical perspectives and add to the robust discourse on AI governance. Although there are some shared terms \n",
      "and definitions, this glossary is separate from the official IAPP Glossary of Privacy Terms .\n",
      "Key Terms for AI Governance\n",
      "TERM DEFINITION\n",
      "Accountability1The obligations and responsibilities of an AI system's developers and deployers to ensure \n",
      "the system operates in a manner that is ethical, fair, transparent and compliant with \n",
      "applicable rules and regulations (see also fairness  and transparency ). Accountability \n",
      "ensures the actions, decisions and outcomes of an AI system can be traced back to the \n",
      "entity responsible for it.\n",
      "AccuracyThe degree to which an AI system correctly performs its intended task. It is the measure \n",
      "of the system's performance and effectiveness in producing correct outputs based on its \n",
      "input data. Accuracy is a critical metric in evaluating the reliability of an AI model, especially \n",
      "in applications requiring high precision, such as medical diagnoses. A B C D E F G H I L M N O P R S T U V W Key termsKey Terms for AI Governance 2A B C D E F G H I L M N O P R S T U V W Key terms\n",
      "TERM DEFINITION\n",
      "Active learningA subfield of AI and machine learning  in which an algorithm selects some of the data \n",
      "it learns from. Instead of learning from all the data it is given, an active learning model \n",
      "requests additional data points that will help it learn the best. \n",
      "Adaptive learningA method that adjusts and tailors educational content to the specific needs, abilities \n",
      "and learning pace of individual students. The purpose of adaptive learning is to provide \n",
      "a personalized and optimized learning experience, catering to the diverse learning \n",
      "styles of students.\n",
      "Adversarial attackA safety  and security risk to the AI model that can be instigated by manipulating the model, \n",
      "such as by introducing malicious or deceptive input data . Such attacks can cause the \n",
      "model to malfunction and generate incorrect or unsafe outputs, which can have significant \n",
      "impacts. For example, manipulating the inputs of a self-driving car may fool the model to \n",
      "perceive a red light as a green one, adversely impacting road safety. \n",
      "AI assuranceA combination of frameworks, policies, processes and controls that measure, evaluate and \n",
      "promote safe, reliable and trustworthy AI. AI assurance schemes may include conformity, \n",
      "impact and risk assessments, AI audits , certifications, testing and evaluation, and \n",
      "compliance with relevant standards.\n",
      "AI auditA review and assessment of an AI system to ensure it operates as intended and complies \n",
      "with relevant laws, regulations and standards. An AI audit can help identify and map risks \n",
      "and offer mitigation strategies.\n",
      "AI governanceA system of laws, policies, frameworks, practices and processes at international, \n",
      "national and organizational levels. AI governance helps various stakeholders implement, \n",
      "manage, oversee and regulate the development, deployment and use of AI technology. \n",
      "It also helps manage associated risks to ensure AI aligns with stakeholders' objectives, \n",
      "is developed and used responsibly and ethically, and complies with applicable legal \n",
      "and regulatory requirements.\n",
      "AlgorithmA procedure or set of instructions and rules designed to perform a specific task or solve \n",
      "a particular problem using a computer. \n",
      "Artificial general \n",
      "intelligenceAI that is considered to have human-level intelligence and strong generalization  \n",
      "capability to achieve goals and carry out a broad range of tasks in different contexts and \n",
      "environments. AGI remains a theoretical field of research. It is contrasted with \"narrow\" \n",
      "AI, which is used for specific tasks or problems. \n",
      " →Acronym: AGIKey Terms for AI Governance 3A B C D E F G H I L M N O P R S T U V W Key terms\n",
      "TERM DEFINITION\n",
      "Artificial intelligenceArtificial intelligence is a broad term used to describe an engineered system that uses \n",
      "various computational techniques to perform or automate tasks. This may include \n",
      "techniques, such as machine learning , in which machines learn from experience, adjusting \n",
      "to new input data  and potentially performing tasks previously done by humans. More \n",
      "specifically, it is a field of computer science dedicated to simulating intelligent behavior \n",
      "in computers. It may include automated decision-making . \n",
      " →Acronym: AI\n",
      "Automated \n",
      "decision-makingThe process of making a decision by technological means without human involvement, \n",
      "either in whole or in part. \n",
      "BiasThere are several types of bias within the AI field. Computational bias or machine bias is \n",
      "a systematic error or deviation from the true value of a prediction that originates from a \n",
      "model's assumptions or the data itself (see also input data ). \n",
      "Cognitive bias refers to inaccurate individual judgment or distorted thinking, while societal \n",
      "bias leads to systemic prejudice, favoritism and/or discrimination in favor of or against an \n",
      "individual or group. Either or both may permeate the model or the system in numerous \n",
      "ways, such as through selection bias, i.e. biases in selecting data for model training. Bias \n",
      "can impact outcomes and pose a risk to individual rights and liberties. \n",
      "Bootstrap aggregatingA machine learning  method that aggregates multiple versions of a model (see also \n",
      "machine learning model ) trained on random subsets of a dataset. This method aims \n",
      "to make a model more stable and accurate. \n",
      " →Sometimes referred to as bagging.\n",
      "ChatbotA form of AI designed to simulate human-like conversations and interactions that \n",
      "uses natural language processing  and deep learning  to understand and respond to \n",
      "text or speech. \n",
      "Classification modelA type of model (see also machine learning model ) used in machine learning  that \n",
      "is designed to take input data and sort it into different categories or classes.\n",
      " →Sometimes referred to as classifiers.\n",
      "ClusteringAn unsupervised machine learning  method in which patterns in the data are identified and \n",
      "evaluated, and data points are grouped accordingly into clusters based on their similarity. \n",
      " →Sometimes referred to as clustering algorithms.\n",
      "ComputeThe processing resources that are available to a computer system. This includes hardware \n",
      "components such as the central processing unit or graphics processing unit. Compute is \n",
      "essential for memory, storage, processing data, running applications, rendering graphics \n",
      "for visual media and powering cloud computing, among others. \n",
      "Computer visionA field of AI that uses computers to process and analyze images, videos and other \n",
      "visual inputs. Common applications of computer vision include facial recognition, \n",
      "object recognition and medical imaging. Key Terms for AI Governance 4A B C D E F G H I L M N O P R S T U V W Key terms\n",
      "TERM DEFINITION\n",
      "Conformity assessmentAn analysis, often performed by an entity independent of a model developer, on an AI \n",
      "system to determine whether requirements, such as establishing a risk management \n",
      "system, data governance, record-keeping, transparency  and cybersecurity practices \n",
      "have been met. \n",
      "ContestabilityThe principle of ensuring AI systems and their decision-making processes can be \n",
      "questioned or challenged by humans. This ability to contest or challenge the outcomes, \n",
      "outputs and actions of AI systems depends on transparency  and helps promote \n",
      "accountability  within AI governance . \n",
      " →Also called redress.\n",
      "CorpusA large collection of texts or data that a computer uses to find patterns, make predictions \n",
      "or generate specific outcomes. The corpus may include structured or unstructured data \n",
      "and cover a specific topic or a variety of topics. \n",
      "Data leakAn accidental exposure of sensitive, personal, confidential or proprietary data. This can \n",
      "be a result of poor security defenses, human error, storage misconfigurations or a lack of \n",
      "robust policies around internal and external data sharing practices. Unlike a data breach, \n",
      "a data leak is unintentional and not done in bad faith.\n",
      "Data poisoningAn adversarial attack in which a malicious user injects false data into a model to \n",
      "manipulate the training process, thereby corrupting the learning algorithm. The goal \n",
      "is to introduce intentional errors into the training dataset, leading to compromised \n",
      "performance and resulting in undesired, misleading or harmful outputs. \n",
      "Data provenanceA process that tracks and logs the history and origin of records in a dataset, encompassing \n",
      "the entire life cycle from its creation and collection to its transformation to its current \n",
      "state. It includes information about sources, processes, actors and methods used to \n",
      "ensure data integrity and quality. Data provenance is essential for data transparency \n",
      "and governance, and it promotes better understanding of the data and eventually the \n",
      "entire AI system.\n",
      "Data qualityThe measure of how well a dataset meets the specific requirements and expectations \n",
      "for its intended use. Data quality directly impacts the quality of AI outputs and the \n",
      "performance of an AI system. High-quality data is accurate, complete, valid, consistent, \n",
      "timely and fit for purpose.\n",
      "Decision treeA type of supervised learning  model used in machine learning (see also machine \n",
      "learning model ) that represents decisions and their potential consequences in a \n",
      "branching structure. \n",
      "Deep learningA subfield of AI and machine learning  that uses artificial neural networks . Deep learning \n",
      "is especially useful in fields where raw data needs to be processed, like image recognition, \n",
      "natural language processing  and speech recognition. Key Terms for AI Governance 5A B C D E F G H I L M N O P R S T U V W Key terms\n",
      "TERM DEFINITION\n",
      "DeepfakesAudio or visual content that has been altered or manipulated using artificial intelligence  \n",
      "techniques. Deepfakes can be used to spread misinformation  and disinformation . \n",
      "Diffusion modelA generative model used in image generation that works by iteratively refining a noise \n",
      "signal to transform it into a realistic image when prompted.\n",
      "Discriminative modelA type of model (see also machine learning model ) used in machine learning  that directly \n",
      "maps input features to class labels and analyzes for patterns that can help distinguish \n",
      "between different classes. It is often used for text classification tasks, like identifying the \n",
      "language of a piece of text or detecting spam. Examples are traditional neural networks , \n",
      "decision trees  and random forest . \n",
      "DisinformationAudio or visual content that is intentionally manipulated or created to cause \n",
      "harm. Disinformation can spread through deepfakes  created by those who have \n",
      "malicious intentions. \n",
      "EntropyThe measure of unpredictability or randomness in a set of data used in machine learning . \n",
      "A higher entropy signifies greater uncertainty in predicting outcomes. \n",
      "Expert systemA form of rules-based AI that draws inferences from a knowledge base provided by \n",
      "human experts to replicate their decision-making abilities within a specific field, like \n",
      "medical diagnoses. \n",
      "ExplainabilityThe ability to describe or provide sufficient information about how an AI system generates \n",
      "a specific output or arrives at a decision in a specific context. Explainability is important in \n",
      "maintaining transparency and trust in AI.\n",
      "Exploratory data analysisData discovery process techniques that take place before training a machine learning \n",
      "model  to gain preliminary insights into a dataset, such as identifying patterns, outliers \n",
      "and anomalies and finding relationships among variables .\n",
      "Fairness1An attribute of an AI system that prioritizes relatively equal treatment of individuals or \n",
      "groups in its decisions and actions in a consistent, accurate and measurable manner. \n",
      "Every model must identify the appropriate standard of fairness that best applies, but most \n",
      "often it means the AI system's decisions should not adversely impact, whether directly or \n",
      "disparately, sensitive attributes like race, gender or religion. \n",
      "Federated learningA machine learning  method that allows models (see also machine learning model ) to be \n",
      "trained on the local data of multiple edge devices. Only the updates of the local model, not \n",
      "the training data itself, are sent to a central location where they are aggregated to improve \n",
      "the global model — a process that is iterated until the global model is fully trained. This \n",
      "process enables better privacy and security controls for the individual user data. Key Terms for AI Governance 6A B C D E F G H I L M N O P R S T U V W Key terms\n",
      "TERM DEFINITION\n",
      "Fine-tuningThe process of taking a pretrained deep learning model and training it further for a \n",
      "specialized task through supervised learning . It involves taking a foundation model  that \n",
      "has already learned general patterns from a large dataset and training it for a specific task \n",
      "using a much smaller and labeled dataset. \n",
      "Foundation modelA large-scale model that has been trained on extensive and diverse datasets to \n",
      "enable broad capabilities, such as language (see also large language model ), vision, \n",
      "robotics, reasoning, search or human interaction, that can function as the base for \n",
      "use-specific applications. \n",
      " →Also called general purpose AI model and frontier AI. \n",
      "GeneralizationThe ability of a model (see also machine learning model ) to understand the underlying \n",
      "patterns and trends in its training data and apply what it has learned to make predictions \n",
      "or decisions about new, unseen data. \n",
      "Generative AIA field of AI that uses deep learning  trained on large datasets to create content, such as \n",
      "written text, code, images, music, simulations and videos, in response to user prompts . \n",
      "Unlike discriminative models , generative AI makes predictions on existing data rather \n",
      "than new data. \n",
      "Greedy algorithmsA type of algorithm  that makes the optimal choice to achieve an immediate objective at a \n",
      "particular step or decision point based on the available information and without regard for \n",
      "the long-term optimal solution. \n",
      "Ground truthThe absolute or objectively known state of a dataset against which the quality of an AI \n",
      "system can be evaluated. It serves as the real-world reference against which the outputs \n",
      "are measured for accuracy  and reliability.\n",
      "HallucinationsInstances in which generative AI  models create seemingly plausible but factually incorrect \n",
      "outputs under the appearance of fact. \n",
      " →Also called confabulations. \n",
      "Human-centric AIAn approach to AI design, development, deployment and use that prioritizes human \n",
      "well-being, autonomy, values and needs. The goal is to develop AI systems that amplify \n",
      "and augment human abilities rather than undermine them.\n",
      "Human-in-the-loopA design paradigm that incorporates human oversight, intervention, interaction or control \n",
      "over the operation and decision-making processes of an AI system. \n",
      " →Acronym: HITL\n",
      "Impact assessmentAn evaluation process designed to identify, understand, document and mitigate \n",
      "the potential ethical, legal, economic and societal implications of an AI system in \n",
      "a specific use case.Key Terms for AI Governance 7A B C D E F G H I L M N O P R S T U V W Key terms\n",
      "TERM DEFINITION\n",
      "InferenceA type of machine learning  process in which a trained model (see also machine learning \n",
      "model ) is used to make predictions or decisions based on input data . \n",
      "Input dataData provided to or directly acquired by a learning algorithm  or model (see also machine \n",
      "learning model ) for the purpose of producing an output. It forms the basis for machine \n",
      "learning models to learn, make predictions and carry out tasks. \n",
      "InterpretabilityThe ability to explain or present a model's reasoning in human-understandable \n",
      "terms. Unlike explainability , which provides an explanation after a decision is made, \n",
      "interpretability emphasizes designing models that inherently facilitate understanding \n",
      "through their structure, features or algorithms. Interpretable models are domain-specific \n",
      "and require significant domain expertise to develop.\n",
      "Large language modelA form of AI that utilizes deep learning  algorithms to create models (see also machine \n",
      "learning model , foundation model  and fine-tuning ) pretrained on massive text datasets \n",
      "for the general purpose of analyzing and learning patterns and relationships among \n",
      "characters, words and phrases to perform text-based tasks. There are generally two \n",
      "types of LLMs: generative models that make text predictions based on the probabilities of \n",
      "word sequences learned from its training data (see also generative AI ) and discriminative \n",
      "models that make classification predictions based on probabilities of data features and \n",
      "weights learned from its training data (see also discriminative model ). The word large \n",
      "generally refers to the model's capacity measured by the number of parameters and to the \n",
      "enormous datasets it is trained on. \n",
      " →Acronym: LLM\n",
      "Machine learningA subfield of AI involving algorithms that iteratively learn from and then make decisions, \n",
      "recommendations, inferences  or predictions based on input data . These algorithms build \n",
      "a model from training data to perform a specific task on new data without being explicitly \n",
      "programmed to do so. \n",
      "Machine learning implements various algorithms that learn and improve by experience \n",
      "in a problem-solving process that includes data collection and preparation, feature \n",
      "engineering, training, testing and validation. Companies and government agencies deploy \n",
      "machine learning algorithms for tasks such as fraud detection, recommender systems, \n",
      "customer inquiries, health care, and transportation and logistics. \n",
      " →Acronym: ML\n",
      "Machine learning modelA learned representation of underlying patterns and relationships in data, created by \n",
      "applying an AI algorithm to a training dataset. The model can then be used to make \n",
      "predictions or perform tasks on new, unseen data. \n",
      "MisinformationFalse audio or visual content that is unintentionally misleading. It can be spread through \n",
      "deepfakes  created by those who lack intent to cause harm. \n",
      "Model cardA brief document that discloses information about an AI model, like explanations about \n",
      "intended use, performance metrics and benchmarked evaluation in various conditions, \n",
      "such as across different cultures, demographics or race (see also system cards ).Key Terms for AI Governance 8A B C D E F G H I L M N O P R S T U V W Key terms\n",
      "TERM DEFINITION\n",
      "Multimodal modelsA type of model used in machine learning  (see also machine learning model ) that can \n",
      "process more than one type of input or output data, or \"modality,\" at the same time. \n",
      "For example, a multimodal model can take both an image and text caption as input and \n",
      "then produce a unimodal output in the form of a score indicating how well the text caption \n",
      "describes the image. These models are highly versatile and useful in a variety of tasks, \n",
      "like image captioning and speech recognition. \n",
      "Natural language \n",
      "processingA subfield of AI that helps computers understand, interpret and apply human language by \n",
      "transforming information into content. It enables machines to translate languages, read \n",
      "text or spoken language, interpret its meaning, measure sentiment, and determine which \n",
      "parts are important for understanding. \n",
      "Neural networksA type of model (see also machine learning model ) used in deep learning  that mimics the \n",
      "way neurons in the human brain interact with multiple processing layers, including at least \n",
      "one hidden layer. This layered approach enables machine-based neural networks to model \n",
      "complex nonlinear relationships and patterns within data. Artificial neural networks have a \n",
      "range of applications, such as image recognition and medical diagnoses. \n",
      "Open-source softwareA decentralized development model that provides the public with free and open access \n",
      "to source code, which can then be viewed, modified and redistributed according to the \n",
      "terms of its respective license. The goal is to promote innovation, transparency, shared \n",
      "collaboration and learning among researchers and technical experts. \n",
      "OverfittingA concept in machine learning  that involves a model (see also machine learning model ) \n",
      "becoming too specific to the training data and unable to generalize to unseen data, \n",
      "which means it can fail to make accurate predictions on new datasets. \n",
      "OversightThe process of effectively monitoring and supervising an AI system to minimize risks, \n",
      "ensure regulatory compliance and uphold responsible practices. Oversight is important for \n",
      "effective AI governance , and mechanisms may include certification processes, conformity \n",
      "assessments and regulatory authorities responsible for enforcement. \n",
      "ParametersThe internal variables an algorithmic model learns from the training data. They are values \n",
      "the model adjusts to during the training process so it can make predictions on new data. \n",
      "Parameters are specific to the architecture of the model. For example, in neural networks , \n",
      "parameters are the weights of each neuron in the network. \n",
      "Post processingSteps performed after a machine learning model  has been run to adjust its output. This \n",
      "can include adjusting a model's outputs or using a holdout dataset — data not used in the \n",
      "training of the model — to create a function run on the model's predictions to improve \n",
      "fairness or meet business requirements. \n",
      "PreprocessingSteps taken to prepare data for training a machine learning model , which can include \n",
      "cleaning the data, handling missing values, normalizing the data, performing feature \n",
      "extraction and encoding categorical variables. Data preprocessing can play a crucial role \n",
      "in improving data quality, mitigating bias, addressing algorithmic fairness concerns and \n",
      "enhancing the performance and reliability of machine learning algorithms. Key Terms for AI Governance 9A B C D E F G H I L M N O P R S T U V W Key terms\n",
      "TERM DEFINITION\n",
      "Prompt An input or instruction provided to an AI model or system to generate an output. \n",
      "Prompt engineeringPrompt engineering is the deliberate process of structuring a prompt or series of prompts \n",
      "to influence model behavior to generate more desirable outputs. \n",
      "Random forestA supervised machine learning (see also supervised learning ) algorithm that builds \n",
      "multiple decision trees  and merges them to get a more accurate and stable prediction. \n",
      "Each decision tree is built with a random subset of the training data (see also bootstrap \n",
      "aggregating ), hence the name random forest. Random forests are helpful to use with \n",
      "datasets that are missing values or are very complex. \n",
      "Red teamingThe process of testing the safety, security and performance of an AI system through an \n",
      "adversarial lens, typically through the simulation of adversarial attacks on the model \n",
      "to evaluate it against certain benchmarks, jailbreak it and try to make it behave in \n",
      "unintended or inappropriate ways. Red teaming reveals security risks, model flaws, biases, \n",
      "misinformation and other harms, and the results of such testing are passed along to the \n",
      "model developers for evaluation and remediation. Developers use red teaming to improve \n",
      "a model before and after releasing it to the public.\n",
      "Reinforcement learningA machine learning  method that trains a model to optimize its actions within a given \n",
      "environment to achieve a specific goal, guided by feedback mechanisms of rewards and \n",
      "penalties. This training is often conducted through trial-and-error interactions or simulated \n",
      "experiences that do not require external data. For example, an algorithm can be trained \n",
      "to earn a high score in a video game by having its efforts evaluated and rated according to \n",
      "success toward the goal. \n",
      "Reinforcement learning \n",
      "with human feedbackThe process of combining the technique of reinforcement learning  with human feedback \n",
      "during the training process. Human feedback is provided on the model's output, often \n",
      "by comparing different outputs for the same prompt  and indicating which output aligns \n",
      "better with human preferences. In reinforcement learning, the model learns by receiving \n",
      "rewards or penalties. Combining this with human feedback provides an additional source \n",
      "of rewards and penalties and helps align the AI's behavior with human preferences \n",
      "and values. \n",
      " →Acronym: RLHF\n",
      "ReliabilityAn attribute of an AI system that ensures it behaves as expected and performs its intended \n",
      "function consistently and accurately, even with new data that it has not been trained on. \n",
      "RoboticsA multidisciplinary field that encompasses the design, construction, operation and \n",
      "programming of robots. Robotics allow AI systems and software to interact with the \n",
      "physical world. \n",
      "RobustnessAn attribute of an AI system that signifies the system's ability to be resilient to, overcome \n",
      "and withstand security attacks. Robustness ensures the system's functionality, \n",
      "performance and accuracy  in a variety of environments and circumstances, even when \n",
      "faced with changed inputs or security attacks. Key Terms for AI Governance 10A B C D E F G H I L M N O P R S T U V W Key terms\n",
      "TERM DEFINITION\n",
      "SafetyA broad term, which may refer to designing, developing and deploying AI systems that \n",
      "minimize AI harms from misinformation, disinformation, deepfakes, hallucinations and \n",
      "other unintended behaviors. It may also refer to mitigating and managing malicious use or \n",
      "rogue behavior. Safety also encompasses the prevention of existential or unexpected risks \n",
      "that may arise from advanced AI capabilities reflected in foundation models . \n",
      "Semi-supervised learningA subset of machine learning  that combines both supervised learning  and unsupervised \n",
      "learning  by training the model on a large amount of unlabeled data and a small amount \n",
      "of labeled data. This avoids the challenges of finding large amounts of labeled data for \n",
      "training the model. Generative AI  commonly relies on semi-supervised learning. \n",
      "Small language modelsA smaller version of their better-known and larger counterparts, large language models . \n",
      "Small is a reference to the size of the models. They have fewer parameters  and require a \n",
      "much smaller training dataset, optimizing them for efficiency and better suiting them for \n",
      "deployment in environments with limited computational resources or for applications that \n",
      "require faster training and inference  time.\n",
      "Supervised learningA subset of machine learning  in which the model (see also machine learning model ) is \n",
      "trained on labeled input data  with known desired outputs. These two groups of data \n",
      "are sometimes called predictors and targets or independent and dependent variables \n",
      "respectively. This type of learning is useful for classification or regression. The former \n",
      "refers to training an AI to group data into specific categories and the latter refers to \n",
      "making predictions by understanding the relationship between two variables. \n",
      "Synthetic dataData generated by a system or model (see also machine learning model ) that generally \n",
      "resembles the structure and statistical properties of real data but without any real-world, \n",
      "identifying information. It is often used for testing or training machine-learning models, \n",
      "particularly in cases with limited, unavailable or too sensitive real-world data. \n",
      "System cardSimilar to a model card , a system card is a brief document that discloses information about \n",
      "how various AI models work together within a network of AI systems, promoting greater \n",
      "explainability of the overall system.\n",
      "T esting dataThe dataset used to test and evaluate a trained model (see also machine learning model ). \n",
      "It is used to assess the performance of the model with new data at the very end of the \n",
      "initial model development process and for future upgrades or variations to the model. \n",
      "Training dataThe dataset used to train a model (see also machine learning model ) so it can accurately \n",
      "predict outcomes, find patterns or identify structures within the training data. \n",
      "Transfer learning modelA type of model (see also machine learning model ) used in machine learning  in which an \n",
      "algorithm learns to perform one task, such as recognizing cats, and then uses that learned \n",
      "knowledge as a basis when learning a different but related task, such as recognizing dogs. Key Terms for AI Governance 11A B C D E F G H I L M N O P R S T U V W Key terms\n",
      "TERM DEFINITION\n",
      "Transformer modelA neural network  architecture that learns context and maintains relationships between \n",
      "sequence data, such as words in a sentence. It does so by leveraging the technique of \n",
      "attention, i.e., focusing on the most important and relevant parts of the input sequence. \n",
      "This helps to improve model accuracy. For example, in language learning tasks, by \n",
      "attending to the surrounding words, the model can comprehend the meaning of a \n",
      "word in the context of the whole sentence. \n",
      "Transparency1A broad term that implies openness, comprehensibility and accountability  in the way AI \n",
      "algorithms function and make decisions. However, the specific meaning of transparency \n",
      "may vary depending on context. \n",
      "May refer to the extent to which information regarding an AI system is made available to \n",
      "stakeholders, including disclosing if AI is used through techniques like watermarking , and \n",
      "explaining how the model works through model or system cards for example. \n",
      "It also refers to maintenance of technical and nontechnical documentation across the \n",
      "AI life cycle to keep track of processes and decision-making, which can also assist with \n",
      "auditability of the AI system. \n",
      "In the open-source context , transparency may refer to making the source code \n",
      "publicly accessible. \n",
      "Trustworthy AIIn most cases, this term is used interchangeably with the terms responsible AI and ethical \n",
      "AI, which all refer to principle-based AI development and AI governance , including the \n",
      "principles of security, safety, transparency , explainability , accountability , privacy and \n",
      "nondiscrimination/nonbias (see also bias), among others. \n",
      "Turing testA test of a machine's ability to exhibit intelligent behavior equivalent to or indistinguishable \n",
      "from that of a human. Alan Turing (1912-1954) originally thought of the test to be an AI's \n",
      "ability to converse through a written text, such that a human reader would not be able to \n",
      "tell a computer-generated response from that of a human. \n",
      "UnderfittingA concept in machine learning  in which a model (see also machine learning model ) fails to \n",
      "fully capture the complexity of the training data. This may result in poor predictive ability \n",
      "and inaccurate outputs. Factors leading to underfitting may include having too few model \n",
      "parameters, having too high a regularization rate, or using an inappropriate or insufficient \n",
      "set of features in the training data. \n",
      "Unsupervised learningA subset of machine learning  in which the model is trained by looking for patterns in an \n",
      "unclassified dataset with minimal human supervision. The AI is provided with preexisting \n",
      "unlabeled datasets and then analyzes those datasets for patterns. This type of learning \n",
      "is useful for training an AI for techniques such as clustering  data, outlier detection, \n",
      "dimensionality reduction, feature learning and principal component analysis.\n",
      "Validation dataA subset of the dataset used to assess the performance of the model (see also machine \n",
      "learning model ) during the training phase. Validation data is used for fine-tuning  the \n",
      "parameters of a model and preventing overfitting before the final evaluation using the \n",
      "test dataset. Key Terms for AI Governance 12A B C D E F G H I L M N O P R S T U V W Key terms\n",
      "TERM DEFINITION\n",
      "VariablesIn the context of machine learning , a variable is a measurable attribute, characteristic \n",
      "or unit that can take on different values. Variables can be numerical/quantitative or \n",
      "categorical/qualitative. \n",
      " →Also called features. \n",
      "VarianceA statistical measure that reflects how far a set of numbers are spread out from their \n",
      "average value in a dataset. A high variance indicates the data points are spread widely \n",
      "around the mean. A low variance indicates the data points are close to the mean. In \n",
      "machine learning, higher variance can lead to overfitting . The trade-off between variance \n",
      "and bias is a fundamental concept in machine learning. Model complexity tends to reduce \n",
      "bias but increase variance. Decreasing complexity reduces variance but increases bias. \n",
      "WatermarkingThe process of embedding subtle or visually imperceptible patterns in AI-generated \n",
      "content or metadata that can only be detected by computers. Watermarking helps with \n",
      "the detection and labelling of AI generated content, promoting transparency.\n",
      "Notes\n",
      "1 Different definition than IAPP privacy training glossary .More resources\n",
      " →AI Governance Center\n",
      " →AI topic page →AI Body of KnowledgeKey Terms for AI Governance 13\n",
      "Find the latest version at iapp.org/resourcesUpdated July 2024.IAPP disclaims all warranties, expressed or implied, with respect to the contents of this material, including any warranties \n",
      "of accuracy, merchantability, or fitness for a particular purpose. Nothing herein should be construed as legal advice. \n",
      "© 2024 IAPP. All rights reserved.Accountability  .....................  1\n",
      "Accuracy   .........................  1\n",
      "Active learning  ....................  2\n",
      "Adaptive learning   .................  2\n",
      "Adversarial attack   .................  2\n",
      "AI assurance  ......................  2\n",
      "AI audit   ..........................  2\n",
      "AI governance   ....................  2\n",
      "Algorithm   ........................  2\n",
      "Artificial general intelligence   . . . . . . . .  2\n",
      "Artificial intelligence   ...............  3\n",
      "Automated decision-making   ........  3\n",
      "Bias   .............................  3\n",
      "Bootstrap aggregating   .............  3\n",
      "Chatbot  ..........................  3\n",
      "Classification model   ...............  3\n",
      "Clustering   ........................  3\n",
      "Compute  .........................  3\n",
      "Computer vision   ..................  3\n",
      "Conformity assessment   ............  4\n",
      "Contestability  .....................  4\n",
      "Corpus  ...........................  4\n",
      "Data leak  .........................  4\n",
      "Data poisoning  ....................  4\n",
      "Data provenance  ..................  4\n",
      "Data quality   ......................  4\n",
      "Decision tree   .....................  4\n",
      "Deep learning  .....................  4\n",
      "Deepfakes  ........................  5\n",
      "Diffusion model  ...................  5\n",
      "Discriminative model   ..............  5Disinformation  ....................  5\n",
      "Entropy   ..........................  5\n",
      "Expert system   ....................  5\n",
      "Explainability   .....................  5\n",
      "Exploratory data analysis  ...........  5\n",
      "Fairness  ..........................  5\n",
      "Federated learning   ................  5\n",
      "Fine-tuning   . . . . . . . . . . . . . . . . . . . . . . .  6\n",
      "Foundation model  .................  6\n",
      "Generalization   ....................  6\n",
      "Generative AI   .....................  6\n",
      "Greedy algorithms  .................  6\n",
      "Ground truth   .....................  6\n",
      "Hallucinations   ....................  6\n",
      "Human-centric AI  ..................  6\n",
      "Human-in-the-loop   ................  6\n",
      "Impact assessment  ................  6\n",
      "Inference  .........................  7\n",
      "Input data  ........................  7\n",
      "Interpretability  ....................  7\n",
      "Large language model   .............  7\n",
      "Machine learning  ..................  7\n",
      "Machine learning model  ............  7\n",
      "Misinformation   ...................  7\n",
      "Model card   .......................  7\n",
      "Multimodal models  ................  8\n",
      "Natural language processing  ........  8\n",
      "Neural networks   ..................  8\n",
      "Open-source software   .............  8\n",
      "Overfitting  ........................  8\n",
      "Oversight   ........................  8Parameters  .......................  8\n",
      "Post processing   ...................  8\n",
      "Preprocessing   ....................  8\n",
      "Prompt   ..........................  9\n",
      "Prompt engineering   ...............  9\n",
      "Random forest  ....................  9\n",
      "Red teaming  ......................  9\n",
      "Reinforcement learning   ............  9\n",
      "Reinforcement learning with \n",
      "human feedback   ..................  9\n",
      "Reliability  .........................  9\n",
      "Robotics   .........................  9\n",
      "Robustness  .......................  9\n",
      "Safety  ...........................  10\n",
      "Semi-supervised learning  ..........  10\n",
      "Small language models  ............  10\n",
      "Supervised learning   ..............  10\n",
      "Synthetic data   ...................  10\n",
      "System card   .....................  10\n",
      "Testing data   .....................  10\n",
      "Training data   ....................  10\n",
      "Transfer learning model  ...........  10\n",
      "Transformer model  ...............  11\n",
      "Transparency  ....................  11\n",
      "Trustworthy AI  ...................  11\n",
      "Turing test  .......................  11\n",
      "Underfitting   .....................  11\n",
      "Unsupervised learning   . . . . . . . . . . . .  11\n",
      "Validation data  ...................  11\n",
      "Variables  ........................  12\n",
      "Variance   ........................  12\n",
      "Watermarking   ...................  12Key terms\n",
      "MCQ 1:\n",
      "**Multiple-Choice Question:**\n",
      "\n",
      "What is the primary purpose of the updated glossary in the IAPP's Key Terms for AI Governance released in July 2024?\n",
      "\n",
      "A) To provide legal advice on AI governance.\n",
      "\n",
      "B) To offer a collection of AI use cases across various industries.\n",
      "\n",
      "C) To present succinct, but nuanced, definitions and explanations for common AI governance terms.\n",
      "\n",
      "D) To summarize the historical development of AI technologies.\n",
      "\n",
      "**Answer:**\n",
      "\n",
      "C) To present succinct, but nuanced, definitions and explanations for common AI governance terms.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Define your prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"Generate a multiple-choice question from the following text: {text}\"\n",
    ")\n",
    "\n",
    "# Initialize the LLM with the chat model\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    api_key=\"API_KEY\"\n",
    ")\n",
    "\n",
    "# Create the LLMChain\n",
    "mcq_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# Function to generate MCQs from text\n",
    "def generate_mcqs_from_text(text, num_questions=10):\n",
    "    paragraphs = text.split(\"\\n\\n\")\n",
    "    print(f\"Total paragraphs: {len(paragraphs)}\")  # Debugging line\n",
    "    mcqs = []\n",
    "    \n",
    "    for i in range(min(num_questions, len(paragraphs))):\n",
    "        # Extract text for each prompt\n",
    "        paragraph_text = paragraphs[i]\n",
    "        print(f\"Processing paragraph {i + 1}: {paragraph_text}\")  # Debugging line\n",
    "        \n",
    "        try:\n",
    "            # Generate MCQ for each paragraph\n",
    "            question = mcq_chain.run({\"text\": paragraph_text})\n",
    "            mcqs.append(question)\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating MCQ for paragraph {i + 1}: {e}\")  # Debugging line\n",
    "    \n",
    "    return mcqs\n",
    "\n",
    "# Example usage\n",
    "pdf_path = \"/kaggle/input/ai-gov-term/key_terms_for_ai_governance.pdf\"\n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n",
    "mcqs = generate_mcqs_from_text(pdf_text, num_questions=10)\n",
    "\n",
    "# Print the generated MCQs\n",
    "for idx, mcq in enumerate(mcqs, 1):\n",
    "    print(f\"MCQ {idx}:\")\n",
    "    print(mcq)\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5531848,
     "sourceId": 9156912,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5532173,
     "sourceId": 9157344,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
